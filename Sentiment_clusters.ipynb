{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tries as a starting point this post here on unsupervised sentiment analysis via clusters of word vectors\n",
    "https://towardsdatascience.com/unsupervised-sentiment-analysis-a38bf1906483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model created by `train_word2vec.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors  = KeyedVectors.load_word2vec_format(\"reddit_w2v_model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have vectors for emojis which is quite nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ðŸ™Œ', 1.0),\n",
       " ('dum', 0.8143207430839539),\n",
       " ('ðŸ’Ž', 0.8083906173706055),\n",
       " ('son', 0.7342033386230469),\n",
       " ('carrying', 0.7328704595565796),\n",
       " ('jk', 0.7314605712890625),\n",
       " ('dry', 0.726060152053833),\n",
       " ('drain', 0.7095533013343811),\n",
       " ('sept', 0.7064850330352783),\n",
       " ('b0t', 0.7048172950744629)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(word_vectors.vectors[word_vectors.index2word.index('ðŸ™Œ')], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to ID two positive / negative clusters from the variety of reddit comment data is not going to happen. We can increase the number and look at what seem like themes - meta talk, meme talk, apparently-serious talk, stats-heavy. This changes over time quite a lot as the dataset grows. Could be linked to upvote numbers and comment volume over time, needs sleeping on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=4, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lose)', 0.675972044467926),\n",
       " ('valid', 0.6677347421646118),\n",
       " ('walking', 0.6415858268737793),\n",
       " ('dems', 0.6213172674179077),\n",
       " ('nefarious', 0.6207584142684937),\n",
       " ('walked', 0.6129131317138672),\n",
       " ('loosing', 0.6119007468223572),\n",
       " ('infinite', 0.6081537008285522),\n",
       " ('hurt', 0.608083963394165),\n",
       " ('dare', 0.6052772998809814),\n",
       " ('failures', 0.6029701232910156),\n",
       " ('lurk', 0.602564811706543),\n",
       " ('gaining', 0.6014528274536133),\n",
       " ('stack', 0.6014478206634521),\n",
       " ('inexperienced', 0.6009200811386108),\n",
       " ('>and', 0.5993832945823669),\n",
       " ('punishment', 0.5966596603393555),\n",
       " ('gamble', 0.5935034155845642),\n",
       " ('ruin', 0.5932648777961731),\n",
       " ('swinging', 0.5930019617080688)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[2], topn=20, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(word_vectors.vocab.keys())\n",
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closeness to the cluster centre, but as above, it's arbitrary\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "      <th>closeness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>[-0.23872057, 0.7668084, -0.06523065, 0.502036...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.121072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people</td>\n",
       "      <td>[0.6937657, -0.08785572, -0.29196194, -0.39732...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.126791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>money</td>\n",
       "      <td>[0.0074918834, 0.2853351, 0.0026786586, 0.3595...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.115928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gme</td>\n",
       "      <td>[-0.00830241, -0.24240829, -1.1237249, -0.7349...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get</td>\n",
       "      <td>[0.9307432, -0.7535146, -0.07598917, 0.1320738...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.121322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stock</td>\n",
       "      <td>[0.22871694, 0.07093796, -0.7372991, -0.411352...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.110766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i'm</td>\n",
       "      <td>[0.43491623, -0.39347756, -0.28166318, 0.50103...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>think</td>\n",
       "      <td>[0.13865502, 0.6003073, 0.11263267, 0.3632528,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.137126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>still</td>\n",
       "      <td>[0.06291361, 0.48377606, -0.43849382, 0.498615...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.107593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>would</td>\n",
       "      <td>[0.86194956, 1.0472965, 0.28914222, 0.32642567...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.107005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words                                            vectors  cluster  \\\n",
       "0    like  [-0.23872057, 0.7668084, -0.06523065, 0.502036...        2   \n",
       "1  people  [0.6937657, -0.08785572, -0.29196194, -0.39732...        2   \n",
       "2   money  [0.0074918834, 0.2853351, 0.0026786586, 0.3595...        2   \n",
       "3     gme  [-0.00830241, -0.24240829, -1.1237249, -0.7349...        0   \n",
       "4     get  [0.9307432, -0.7535146, -0.07598917, 0.1320738...        2   \n",
       "5   stock  [0.22871694, 0.07093796, -0.7372991, -0.411352...        0   \n",
       "6     i'm  [0.43491623, -0.39347756, -0.28166318, 0.50103...        2   \n",
       "7   think  [0.13865502, 0.6003073, 0.11263267, 0.3632528,...        2   \n",
       "8   still  [0.06291361, 0.48377606, -0.43849382, 0.498615...        0   \n",
       "9   would  [0.86194956, 1.0472965, 0.28914222, 0.32642567...        2   \n",
       "\n",
       "   closeness_score  \n",
       "0         0.121072  \n",
       "1         0.126791  \n",
       "2         0.115928  \n",
       "3         0.125775  \n",
       "4         0.121322  \n",
       "5         0.110766  \n",
       "6         0.100814  \n",
       "7         0.137126  \n",
       "8         0.107593  \n",
       "9         0.107005  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[['words', 'cluster']].to_csv('sentiment_dictionary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
