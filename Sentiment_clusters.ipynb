{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tries as a starting point this post here on unsupervised sentiment analysis via clusters of word vectors\n",
    "https://towardsdatascience.com/unsupervised-sentiment-analysis-a38bf1906483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from glove import Glove\n",
    "from kmeans_pytorch import kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sentiment_anomaly.models import train_torch_vocab\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model created by `train_word2vec.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors  = KeyedVectors.load_word2vec_format(\"reddit_w2v_model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have vectors for emojis which is quite nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('üôå', 1.0),\n",
       " ('üôåüèª', 0.6535108685493469),\n",
       " ('‚úã', 0.652143120765686),\n",
       " ('üíé', 0.6348857879638672),\n",
       " ('üçÜ', 0.630488395690918)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(word_vectors.vectors[word_vectors.index2word.index('üôå')], topn=5, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to ID two positive / negative clusters from the variety of reddit comment data is not going to happen. We can increase the number and look at what seem like themes - meta talk, meme talk, apparently-serious talk, stats-heavy. This changes over time quite a lot as the dataset grows. You could create sets of embeddings over time slices and look at their relative distance from reference clusters or from one another. Could be linked to upvote numbers and comment volume over time, needs sleeping on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=4, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('money', 0.4843536615371704),\n",
       " ('think', 0.43711191415786743),\n",
       " ('sell', 0.434577077627182),\n",
       " ('lose', 0.4340251088142395),\n",
       " ('people', 0.4328373074531555),\n",
       " ('loose', 0.42213934659957886),\n",
       " ('know', 0.4151310920715332),\n",
       " ('happen', 0.4144483804702759),\n",
       " ('really', 0.40265196561813354),\n",
       " ('want', 0.394616961479187),\n",
       " ('gamble', 0.3945499062538147),\n",
       " ('make', 0.3851986825466156),\n",
       " ('understand', 0.3792017698287964),\n",
       " ('possible', 0.37648141384124756),\n",
       " ('squeeze', 0.3753488063812256),\n",
       " ('blame', 0.37441205978393555),\n",
       " ('still', 0.36940059065818787),\n",
       " ('stock', 0.36777323484420776),\n",
       " ('betting', 0.36734893918037415),\n",
       " ('hedges', 0.3668730854988098)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[2], topn=20, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(word_vectors.vocab.keys())\n",
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closeness to the cluster centre, but as above, it's arbitrary\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "      <th>closeness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>[-0.10896601, -0.4989108, -0.816069, 0.6278063...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.109177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people</td>\n",
       "      <td>[0.05315982, -0.9963219, -1.1672673, -0.550229...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.094861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gme</td>\n",
       "      <td>[0.09548321, -0.55390525, -1.3246208, 0.112597...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.097914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>money</td>\n",
       "      <td>[1.0587951, -1.2309575, -1.3329929, 0.24446851...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.084312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get</td>\n",
       "      <td>[-0.59698033, -1.3145387, -1.1092944, -0.36285...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.091951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stock</td>\n",
       "      <td>[1.2761588, -0.9259336, -1.6981211, 0.03803802...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.082326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>think</td>\n",
       "      <td>[0.28200936, 0.41803923, 0.26620647, 0.8017928...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.096865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>would</td>\n",
       "      <td>[-0.08824884, 0.83257955, -0.52572507, 0.68127...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.080834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shares</td>\n",
       "      <td>[0.23181276, 0.5602848, -1.1762869, -0.5062161...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.072099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>still</td>\n",
       "      <td>[-0.6590462, -0.11133627, -0.4280134, 0.384516...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words                                            vectors  cluster  \\\n",
       "0    like  [-0.10896601, -0.4989108, -0.816069, 0.6278063...        2   \n",
       "1  people  [0.05315982, -0.9963219, -1.1672673, -0.550229...        2   \n",
       "2     gme  [0.09548321, -0.55390525, -1.3246208, 0.112597...        2   \n",
       "3   money  [1.0587951, -1.2309575, -1.3329929, 0.24446851...        2   \n",
       "4     get  [-0.59698033, -1.3145387, -1.1092944, -0.36285...        2   \n",
       "5   stock  [1.2761588, -0.9259336, -1.6981211, 0.03803802...        2   \n",
       "6   think  [0.28200936, 0.41803923, 0.26620647, 0.8017928...        2   \n",
       "7   would  [-0.08824884, 0.83257955, -0.52572507, 0.68127...        2   \n",
       "8  shares  [0.23181276, 0.5602848, -1.1762869, -0.5062161...        3   \n",
       "9   still  [-0.6590462, -0.11133627, -0.4280134, 0.384516...        2   \n",
       "\n",
       "   closeness_score  \n",
       "0         0.109177  \n",
       "1         0.094861  \n",
       "2         0.097914  \n",
       "3         0.084312  \n",
       "4         0.091951  \n",
       "5         0.082326  \n",
       "6         0.096865  \n",
       "7         0.080834  \n",
       "8         0.072099  \n",
       "9         0.086400  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[['words', 'cluster']].to_csv('sentiment_dictionary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the glove model created with `train_glove.py` - less intuitive than word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('together', 0.8503645499106047),\n",
       " ('stonker', 0.833585989646089),\n",
       " ('strong', 0.7843598709353422),\n",
       " ('ape', 0.7447651565484497),\n",
       " ('planet', 0.7352073987340947),\n",
       " ('purpose', 0.7232556207133627),\n",
       " ('nanners', 0.6463758844633478),\n",
       " ('band', 0.6295576290415956),\n",
       " ('idiots', 0.6164448270558343)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove = Glove.load('reddit.glove.model')\n",
    "\n",
    "glove.most_similar('üôå', number=10)\n",
    "glove.most_similar('apes', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It did say this was experimental\n",
    "# glove.most_similar_paragraph(['apes', 'together', 'strong'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach to GloVe, this involves a set of word vectors generated separately with the Stanford CoreNLP implementation and passed to a torchtext.vocab - see the docstrings in `sentiment_anomaly.models` for info. A short-term copout because the vocabulary gets rebuilt on the fly but the vectors don't "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75703lines [00:08, 9003.90lines/s] \n"
     ]
    }
   ],
   "source": [
    "voc = train_torch_vocab(vectors='vectors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 8250),\n",
       " ('people', 7929),\n",
       " ('gme', 6691),\n",
       " ('money', 6173),\n",
       " ('get', 5680),\n",
       " ('would', 4762),\n",
       " ('stock', 4593),\n",
       " ('think', 4521),\n",
       " ('one', 4389),\n",
       " (\"i'm\", 4316)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1767, -0.0937,  0.0285,  ..., -0.1350, -0.2213,  0.1102],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.6638,  0.0854,  0.9071,  ...,  0.0020,  0.4532, -0.9754],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.2047)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(voc.vectors[voc['sell']] - voc.vectors[voc['shares']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5992)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(voc.vectors[voc['üôå']] - voc.vectors[voc['üíé']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda:0..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[running kmeans]: 1000it [00:39, 40.03it/s, center_shift=nan, iteration=1000, tol=0.000100]"
     ]
    }
   ],
   "source": [
    "cluster_ids_x, cluster_centers = kmeans(\n",
    "    X=voc.vectors, num_clusters=4, distance='cosine', device=torch.device('cuda:0'), iter_limit=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
